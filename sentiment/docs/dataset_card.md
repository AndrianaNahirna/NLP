# Dataset Card: Sentiment Analysis

## Назва проєкту
Аналіз тональності українських відгуків про товари (Ukrainian User Review Sentiment Analysis).

## Задача
**Задача A: Класифікація текстів (тональність).**
* **Input:** Текст відгуку користувача.
* **Output:** Мітка тональності: `positive` або `negative`.

## Джерело даних
[Ukrainian User Review Sentiment Analysis Dataset (Kaggle)](https://www.kaggle.com/datasets/alexsukhrin/ukrainian-user-review-sentiment-analysis-dataset).
Датасет містить відгуки з українських маркетплейсів.

## Обсяг
* **Кількість текстів:** 3034.
* **Кількість класів:** 2 (`negative`: 1922, `positive`: 1112).
* **Середня довжина:** ~164 слова / ~1097 символів.

## Мова та Домени
* **Мова:** Українська (UA).
* **Домен:** Відгуки про побутову техніку, електроніку та інші товари.

## Очищення (v2)
Виконано глибоку обробку тексту за допомогою кастомного пайплайну (`TextPreprocessor`):
1. **Базове очищення:** Декодування HTML-сутностей та видалення технічного сміття (фрази "розгорнути", "читати далі", "відповідь" тощо).
2. **Нормалізація символів:** Заміна латинських гомогліфів на кириличні аналоги, уніфікація всіх типів апострофів до стандартного `'`.
3. **Обробка регістру та пунктуації:** Зниження регістру для слів, написаних Caps Lock (із збереженням оригінального регістру для назв моделей, що містять цифри). Стиснення надлишкової пунктуації (`!!!` -> `!!`, `.....` -> `...`) та виправлення пробілів перед розділовими знаками.
4. **Форматування інтервалів:** Додавання пробілів після адресних скорочень (напр., `м. Київ`) та відділення чисел від одиниць виміру/валют (напр., `100 грн`, `64 gb`).
5. **Маскування PII (Конфіденційних даних):** Усі чутливі дані та ідентифікатори замінено на безпечні токени: `<EMAIL>`, `<URL>`, `<PHONE>`, `<ID>`.
6. **Sentence Splitting:** Текст розбито на окремі речення з урахуванням захисту від хибних розривів на відомих українських скороченнях (ім., вул., грн., тощо) та десяткових числах/версіях.

## Ризики
1. **Дисбаланс класів:** Негативних відгуків значно більше, ніж позитивних (1922 vs 1112). Це залишається головним викликом для майбутньої моделі, оскільки вона може бути упередженою в бік негативного класу.
2. **Втрата контексту через маскування:** Хоча токен `<ID>` приховує номери замовлень, у поодиноких випадках він може замаскувати важливі для тональності числові показники, якщо вони нестандартно відформатовані.
3. **Дублікати:**  Перед навчанням їх необхідно видалити.

## План наступного кроку
1. **Балансування датасету:** Вирівняти кількість прикладів у класах (наприклад, через downsampling негативного класу або додавання ваг класам під час навчання).
2. **Векторизація текстів:** Перетворити очищені тексти у числовий формат (TF-IDF, Word2Vec або використання готових ембедингів з трансформерів).
3. **Побудова Baseline-моделі:** Навчити базові алгоритми класифікації (наприклад, Logistic Regression або Naive Bayes) та оцінити їхню точність на валідаційній вибірці.