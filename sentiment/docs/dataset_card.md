# Dataset Card: Sentiment Analysis

## Назва проєкту
Аналіз тональності українських відгуків про товари (Ukrainian User Review Sentiment Analysis).

## Задача
**Задача A: Класифікація текстів (тональність).**
* **Input:** Текст відгуку користувача.
* **Output:** Мітка тональності: `positive` або `negative`.

## Джерело даних
[Ukrainian User Review Sentiment Analysis Dataset (Kaggle)](https://www.kaggle.com/datasets/alexsukhrin/ukrainian-user-review-sentiment-analysis-dataset).
Датасет містить відгуки з українських маркетплейсів.

## Обсяг
* **Кількість текстів:** 3034.
* **Кількість класів:** 2 (`negative`: 1922, `positive`: 1112).
* **Середня довжина:** ~164 слова / ~1097 символів.

## Мова та Домени
* **Мова:** Українська (UA), з наявністю суржику та російськомовних вкраплень.
* **Домен:** Відгуки про побутову техніку, електроніку та інші товари.

## Очищення (v2)
Виконано глибоку обробку тексту за допомогою кастомного пайплайну (`TextPreprocessor`):
1. **Базове очищення:** Декодування HTML-сутностей та видалення технічного сміття (фрази "розгорнути", "читати далі", "відповідь" тощо).
2. **Нормалізація символів:** Заміна латинських гомогліфів на кириличні аналоги, уніфікація всіх типів апострофів до стандартного `'`.
3. **Обробка регістру та пунктуації:** Зниження регістру для слів, написаних Caps Lock. Стиснення надлишкової пунктуації (`!!!` -> `!!`, `.....` -> `...`) та виправлення пробілів перед розділовими знаками.
4. **Форматування інтервалів:** Додавання пробілів після адресних скорочень (напр., `м. Київ`) та відділення чисел від одиниць виміру/валют.
5. **Маскування PII (Конфіденційних даних):** Усі чутливі дані та ідентифікатори замінено на безпечні токени: `<EMAIL>`, `<URL>`, `<PHONE>`, `<ID>`.
6. **Sentence Splitting:** Текст розбито на окремі речення з урахуванням захисту від хибних розривів на відомих українських скороченнях та десяткових числах.

## Лінгвістичні ознаки (v3) та Lemma/POS Decision
За допомогою бібліотеки **Stanza** (модель `uk`) датасет було збагачено лінгвістичними ознаками:
* Згенеровано `lemma_text` (текст, зведений до початкових форм).
* Згенеровано `pos_seq` (послідовність частин мови, напр., `NOUN VERB ADJ`).

**Фінальне рішення щодо Lemma/POS (Lemma/POS Decision):**
* **Використовуємо леми:** У ході експериментів доведено, що використання `lemma_text` покращує точність класифікатора (Accuracy зросла на +2.80% при обмеженому словнику TF-IDF). Лематизація ефективно зменшує розрідженість даних, дозволяючи моделі фокусуватися на сенсі емоційних слів.
* **POS-теги відкидаємо:** Використання POS-тегів та граматичних біграмів для генерації ознак призвело до падіння метрик (-2.64%), оскільки вони створюють інформаційний шум і витісняють корисні слова з лімітованого словника.

## Ризики
1. **Дисбаланс класів:** Негативних відгуків значно більше, ніж позитивних (1922 vs 1112). Це залишається головним викликом, оскільки модель може бути упередженою в бік негативного класу.
2. **Втрата контексту через маскування:** Хоча токен `<ID>` приховує номери замовлень, у поодиноких випадках він може замаскувати важливі для тональності числові показники.
3. **Обмеження лематизатора:** Stanza погано розпізнає повністю російськомовні відгуки, англійські назви брендів та суржик, іноді генеруючи хибні леми або позначаючи їх тегом `X` (Other).

## План наступного кроку
1. **Боротьба з дисбалансом:** Вирівняти кількість прикладів у класах (наприклад, через додавання параметра `class_weight='balanced'` у класифікатор).
2. **Тюнінг гіперпараметрів:** Використати `GridSearchCV` для пошуку оптимальних параметрів моделі Logistic Regression (наприклад, сили регуляризації `C`) та розміру словника `TF-IDF`.
3. **Експерименти з ембедингами:** Спробувати складніші методи векторизації текстів (Word2Vec, FastText) для кращого розуміння семантики слів у порівнянні з класичним TF-IDF.