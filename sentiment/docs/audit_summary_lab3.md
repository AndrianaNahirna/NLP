# Audit Summary: Lab 3 (Lemma / POS Baseline)

## 1. Загальна інформація
* **Напрям:** Задача A (Класифікація текстів - Sentiment Analysis)
* **Інструмент:** Stanza (українська модель, процесори: tokenize, pos, lemma)

## 2. Результати Baseline-моделей
Використано TF-IDF (`max_features=1200`) + Logistic Regression.

* **Baseline 1 (без лем, processed_v2):** 
  * Accuracy: 0.8484 
  * Macro-F1: 0.8253
* **Baseline 2 (з лемами, lemma_text):**    
  * Accuracy: 0.8748 
  * Macro-F1: 0.8572
* **Baseline 3 (processed_v2 + POS n-grams):** 
  * Accuracy: 0.8204 
  * Macro-F1: 0.7865

**Різниця:** Лематизація покращила Accuracy на **+2.80%**, а додавання POS n-grams погіршило на **-2.64%**.

## 3. Аналіз помилок (Error Analysis)
Під час перевірки лематизації (Stanza) виявлено такі систематичні проблеми:
1. **Бренди та англійські вставки:** Назви техніки (gаlаху, Меіzu, Хіаоmі) та англійські слова стабільно не розпізнаються, отримують тег `X` (Other) і не лематизуються.
2. **Російська мова:** Україномовна модель Stanza не справляється з російськими відгуками. Більшість слів отримують тег `X` або хибні "українізовані" леми (напр., 'чернуй' замість 'черную').
3. **Суржик та одруківки:** Слова на кшталт 'дрставка', 'празднік' залишаються як є, або отримують хибну лему ('пріч' замість 'причому').
4. **Спецсимволи та дати:** Модель надмірно токенізує дати (10.12.2017 -> 10 . 12 . 2017) та розбиває наш маскувальний тег з ЛР2 (`<ID>` -> `< id >`).
5. **Вплив на метрики:** Попри цей шум на неформатних токенах, лематизатор чудово справляється з основною масою правильних українських слів, що загалом дало позитивний приріст метрик.

## 4. Висновок: 
У задачі класифікації (Sentiment Analysis) використання лематизованого тексту (`lemma_text`) суттєво покращило результати baseline-моделі, піднявши Accuracy на +2.80% (з 0.8484 до 0.8748). Це покращення відбулося завдяки зменшенню розрідженості простору ознак при жорстко обмеженому словнику (`max_features=1200`), оскільки лематизація успішно об'єднала різні форми емоційних слів у єдині сутності. Натомість використання POS-тегів у комбінації з текстом та біграмами (Baseline 3) призвело до помітного погіршення метрик (падіння Accuracy на -2.64%). Згенеровані граматичні n-грами витіснили з лімітованого словника семантично важливі слова, перетворившись на інформаційний "шум". Також аналіз помилок показав, що лематизатор Stanza часто генерував хибні леми або теги на повністю російськомовних відгуках, специфічних брендах та суржику, але загальному росту метрик це не зашкодило. Отже, фінальне рішення для проєкту — **"використовувати леми"** як основний вхідний текст для навчання класифікатора. Від інтеграції POS-тегів у фічі повністю відмовитись, оскільки вони не додають цінності у поточній конфігурації.
