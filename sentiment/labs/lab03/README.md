# LPNU NLP Lab #3: Lemma & POS Baseline

**1. Напрям проєкту**
Напрям А: Класифікація текстів (Sentiment Analysis — аналіз тональності українських відгуків).

**2. Інструмент для Lemma/POS**
Використано бібліотеку **Stanza** (українська модель, процесори: `tokenize, pos, lemma`).

**3. Побудовані Baseline-моделі**
Для класифікації використано `TF-IDF Vectorizer` (`max_features=1200`) + `Logistic Regression`. Було побудовано 3 підходи:
* Baseline 1: навчання на сирому очищеному тексті (`processed_v2`).
* Baseline 2: навчання на лематизованому тексті (`lemma_text`).
* Baseline 3: навчання на тексті з додаванням POS-тегів та біграмів (`ngram_range=(1,2)`).

**4. Основні цифри "до/після"**
* **До (Baseline 1 - без лем):** Accuracy: 0.8484 | Macro-F1: 0.8253
* **Після (Baseline 2 - з лемами):** Accuracy: 0.8748 | Macro-F1: 0.8572 *(Приріст: +2.80% Accuracy)*
* **Після (Baseline 3 - з POS):** Accuracy: 0.8204 | Macro-F1: 0.7865 *(Падіння: -2.64% Accuracy)*

**5. Висновок**
* **Використовуємо леми:** Лематизований текст (`lemma_text`) беремо як основний вхідний текст для класифікатора. При обмеженому словнику (1200 слів) лематизація зменшує розрідженість даних і суттєво покращує метрики (+2.80%), фокусуючи модель на сенсі, а не на закінченнях.
* **POS-теги не беремо:** Використання POS-тегів як фічей погіршило результати (-2.64%), оскільки граматичні n-грами створили інформаційний шум і витіснили корисні емоційні слова зі словника. Тому для навчання від них повністю відмовляємося.