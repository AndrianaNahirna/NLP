# LPNU NLP Lab #2: Text Preprocessing & Normalization

## 1. Яка задача і що у вашому text полі
* **Задача:** Задача A (Класифікація текстів — аналіз тональності / Sentiment Analysis). 
* **Поле `text`:** Містить сирі відгуки користувачів про різноманітні товари (електроніку, побутову техніку тощо) з українських маркетплейсів. Тексти часто містять емоційне забарвлення, сленг, помилки, специфічну пунктуацію та технічні характеристики.

## 2. Як запустити ноутбук в Colab
1. Відкрийте файл `notebooks/lab2_cleaning_normalization.ipynb` у Google Colab.
2. Натисніть **Runtime -> Run all**. 
   * *Примітка:* Код автоматично налаштує середовище: склонує репозиторій з GitHub, завантажить необхідні модулі та підтягне сирий датасет із публічної папки на Google Drive за допомогою `gdown`. Ніяких ручних налаштувань шляхів не потрібно.

## 3. Які правила очистки/нормалізації додано
* **Базове очищення:** Декодування HTML-сутностей та видалення технічних слів-артефактів парсингу ("розгорнути", "читати далі").
* **Нормалізація:** Уніфікація апострофів (до `'`), заміна латинських гомогліфів на кириличні (напр., `y` -> `у`), стиснення емоційної пунктуації (`!!!` -> `!!`).
* **Caps Lock:** Зниження регістру для слів, що написані повністю великими літерами (ігноруючи абревіатури та моделі техніки з цифрами).
* **Інтервали:** Додавання пробілів у злиплих адресах (`м.Київ`) та між числами і валютами/одиницями виміру (`100грн` -> `100 грн`).
* **Маскування (PII):** Заміна чутливих та специфічних даних на теги `<EMAIL>`, `<URL>`, `<PHONE>`, `<ID>`.
* **Розумний Sentence Split:** Розбиття на речення регулярним виразом, який ігнорує відомі українські скорочення (ім., вул., м., грн. тощо) та дробові числа/версії.

## 4. Які 5 найболючіших edge cases у датасеті
1. **Приховані гомогліфи у назвах брендів:** Користувачі міксували розкладки (наприклад, `моyо`, де `y` — латинська). Це ламало ідемпотентність під час зміни регістру та заміни гомогліфів.
2. **Розрив речень на скороченнях:** Стандартний спліт по крапці розривав речення на адресах (напр., `Прийшов у м. Київ`) та ініціалах. Довелося писати RegEx із Negative Lookbehind по словнику з 19 скорочень.
3. **Назви моделей техніки капсом:** Зниження регістру для емоційних криків (напр., `ЖАХЛИВО`) випадково псувало назви моніторів чи ноутбуків (`DELL U2415`). Вирішено додаванням умови, що ігнорує слова з цифрами.
4. **Злипле форматування цін та об'ємів:** Написання формату `39000грн` або `64GB` без пробілів створювало унікальні, але неінформативні токени. 
5. **Агресивна емоційна пунктуація:** Тексти містили конструкції на кшталт `? ! ? . . . .`, які створювали шум. Вирішено шляхом попереднього видалення пробілів перед знаками та подальшого їх стиснення до еталонних `...`, `!!`, `??`.

## 5. Що стало краще “після”
*(Дані на основі порівняльної статистики пайплайну)*
* **Очищення від сміття (Довжина текстів):** Максимальна кількість символів у найдовшому тексті зменшилась із **6070** до **5960**, а середня довжина впала з **1096.7** до **1034.4** символів. Це доводить, що алгоритм успішно "зрізав" зайві пробіли, технічні артефакти HTML та стиснув емоційну пунктуацію, не втративши при цьому жодного рядка (0 порожніх текстів після обробки).
* **Маскування ідентифікаторів (PII):** Успішно знайдено та приховано **431** тег `<ID>` та **107** посилань `<URL>` (а також 37 номерів телефонів і 30 email-адрес). Це кардинально зменшить розмір словника (vocabulary size) для моделі, оскільки унікальні номери замовлень і посилання більше не вважатимуться окремими словами-ознаками.
* **Дублікати:** Кількість точних дублікатів залишилася стабільною (**9** записів, або 0.30%). Це свідчить про те, що датасет відпочатку не був засмічений спамом, який би відрізнявся лише Caps Lock-ом чи кількістю пробілів.